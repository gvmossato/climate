# ğŸ‚ Climate

Projeto desenvolvido para a disciplina **PTC3567 â€” CiÃªncia dos Dados em AutomaÃ§Ã£o e Engenharia** da Poli-USP buscando estudar a evoluÃ§Ã£o histÃ³rica do aquecimento global e sua relaÃ§Ã£o com a concentraÃ§Ã£o mÃ©dia de gÃ¡s carbÃ´nico global. A anÃ¡lise foi conduzida com dados oriundos de distintas fontes e em volume massivo, sob a pretensÃ£o de entender o panorÃ¢ma histÃ³rico e elaborar prediÃ§Ãµes a cerca do panorÃ¢ma futuro, com o auxÃ­lio de algorÃ­timos de InteligÃªcia Artifical.

# ğŸ§™ Colaboradores

A realizaÃ§Ã£o desse projeto foi possÃ­vel por meio do trabalho de:

* Gabriel Trellesse
* [Gabriel Mossato](https://github.com/gvmossato)
* [Juliana Kodono](https://github.com/julianakodono)

# ğŸ’½ Datasets

Duas foram as principais fontes de dados:

* [Climate Change: Earth Surface Temperature Data](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data), um dataset pÃºblico disponibilizado atravÃ©s do Kaggle que em sua versÃ£o mais discretizada possui aproximadamente **8.6 milhÃµes de registros**, que contemplam leituras mensais desde 1750 atÃ© 2013, localizadas por latitude e longitude.

* [Global monthly distributions of atmospheric CO2 concentrations under the historical and future scenarios](https://zenodo.org/record/5021361), disponibilizado via Zenodo, o dataset histÃ³rico utilizado conta com **127 milhÃµes de registros**, sÃ£o dados que partem de 1850 indo atÃ© 2013 e fazem um mapeamento com 1 grau de discretizaÃ§Ã£o, em latitude e longitude.

# ğŸ“ Estrutura

O repositÃ³rio encontra-se organizado como abaixo:

```
ğŸ“ src
â”œâ”€â”€ ğŸ“ integrate
â”‚   â”œâ”€â”€ ğŸ“ data
â”‚   â”œâ”€â”€ ğŸ“ out
â”‚   â”œâ”€â”€ ğŸ convert.ipynb
â”‚   â”œâ”€â”€ ğŸ parse.ipynb
â”‚   â””â”€â”€ ğŸ integrate.ipynb
â””â”€â”€ ğŸ“ analisys
    â”œâ”€â”€ ğŸ“ data
    â””â”€â”€ ğŸ explore.ipynb
```

No diretÃ³rio `integrate` existem os notebooks utilizados para fazer a integraÃ§Ã£o dos datasets, que envolve:

1. A conversÃ£o de NetCDF para CSV;
2. O *parsing* das tabelas para adequaÃ§Ã£o de suas colunas entre cada fonte; 
3. A junÃ§Ã£o de fato das tabelas.

AlÃ©m disso, os dados de entrada sÃ£o sempre colocados nas pastas `data` e, quando existem, os dados de saÃ­da sÃ£o salvos em `out`. Finalmente, `analisys` apresenta o processo de anÃ¡lise desses dados previamente tratados e integrados.

# ğŸ“¦ DependÃªncias

O detalhamento das dependÃªncias encontra-se em [`requirements.txt`](https://github.com/gvmossato/climate/blob/main/requirements.txt), sendo as principais:

* [IPython](https://ipython.org/)
* [PySpark](https://spark.apache.org/docs/latest/api/python/)
* [Xskipper](https://xskipper.io/1.3.0/)
* [Pandas](https://pandas.pydata.org/)
* [Xarray](https://docs.xarray.dev/en/stable/)
* [Plotly](https://plotly.com/python/)

# âš™ï¸ InstalaÃ§Ã£o

Ã‰ necessÃ¡rio clonar o repositÃ³rio:

```
git clone git@github.com:gvmossato/climate.git
```

*(Opcional)* Criar e ativar um ambiente virtual:

```
python -m venv env
```

```
env/Scripts/activate
```

E instalar suas dependÃªncias:

```
pip install -r requirements.txt
```

Demais instruÃ§Ãµes estÃ£o listadas no notebook [`src/integrate/parse.ipynb`](https://github.com/gvmossato/climate/blob/main/src/integrate/parse.ipynb) e podem ser necessÃ¡rias ou nÃ£o de acordo com o que se prentende executar.
